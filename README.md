# Awesome-Anything
[![Awesome Anything](https://img.shields.io/badge/Awesome-Anything-blue)](https://github.com/topics/awesome)

A curated list of **general AI methods for Anything**: AnyObject, AnyGeneration, AnyModel, etc.

Contributions are welcome!

## AnyObject

| Title & Authors | Intro | Useful Links |
|:----|  :----: | :---:|
| [**Segment Anything**](https://arxiv.org/abs/2304.02643) <br> *Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick* | ![intro](https://github.com/facebookresearch/segment-anything/blob/main/assets/masks2.jpg?raw=true) | [[Github](https://github.com/facebookresearch/segment-anything)] <br> [[Page](https://segment-anything.com/)] <br> [[Demo](https://segment-anything.com/demo)] |
| [[**Grounded-SAM (Project)**](https://github.com/IDEA-Research/Grounded-Segment-Anything)] <br> [**Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection**](https://arxiv.org/abs/2303.05499) <br> *Shilong Liu and Zhaoyang Zeng and Tianhe Ren and Feng Li and Hao Zhang and Jie Yang and Chunyuan Li and Jianwei Yang and Hang Su and Jun Zhu and Lei Zhang* | ![intro](https://github.com/IDEA-Research/Grounded-Segment-Anything/raw/main/assets/grounded_sam_demo3_demo4.png) | [[Github](https://github.com/IDEA-Research/Grounded-Segment-Anything)] <br> [[Demo]](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb) |
| [[**SegGPT (Project)**](https://github.com/baaivision/Painter)] <br> [**SegGPT: Segmenting Everything In Context**](https://arxiv.org/abs/2304.03284) <br> *Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang* | <img width="903" alt="image" src="https://user-images.githubusercontent.com/18592211/230897227-c797f375-a44d-4536-a06b-41f0d9f4dbc4.png"> | [Github](https://github.com/baaivision/Painter) |
| [[**segment-anything-video (Project)**](https://github.com/kadirnar/segment-anything-video)] <br> Kadir Nar | ![intro](https://github.com/kadirnar/segment-anything-pip/releases/download/v0.2.2/metaseg_demo.gif)  | [[Github](https://github.com/kadirnar/segment-anything-video)] |
| [[**segment-any-moving (Project)**](https://github.com/achalddave/segment-any-moving)] <br> [**Towards Segmenting Anything That Moves**](https://arxiv.org/abs/1902.03715) <br> *Achal Dave, Pavel Tokmakov, Deva Ramanan* | [<img src="http://www.achaldave.com/projects/anything-that-moves/videos/c95cd17749.gif" width="32%" />](http://www.achaldave.com/projects/anything-that-moves/videos/c95cd17749.mp4)<img src="http://www.achaldave.com/projects/anything-that-moves/videos/e0bdb5dfae.gif" width="32%" /> | [[Github](https://github.com/achalddave/segment-any-moving)] |


## AnyGeneration
| Title & Authors | Intro | Useful Links |
|:----|  :----: | :---:|
| [[**Stable-Diffusion (Project)**](https://github.com/CompVis/stable-diffusion)] <br> [**High-Resolution Image Synthesis with Latent Diffusion Models**](https://arxiv.org/abs/2112.10752) <br> *Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj√∂rn Ommer* | ![intro](https://r2.stablediffusionweb.com/images/stable-diffusion-demo-2.webp) | [[Github](https://github.com/CompVis/stable-diffusion)] <br> [[Page](https://stablediffusionweb.com/)] <br> [[Demo](https://stablediffusionweb.com/#demo)] |
| [[**ControlNet (Project)**](https://github.com/lllyasviel/ControlNet)] <br> [**Adding Conditional Control to Text-to-Image Diffusion Models**](https://arxiv.org/abs/2302.05543) <br> *Lvmin Zhang, Maneesh Agrawala* | ![intro](https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_16_output_1.jpeg) | [[Github](https://github.com/lllyasviel/ControlNet)] <br>  [[Demo](https://huggingface.co/spaces/hysts/ControlNet)] |
| [**GigaGAN: Large-scale GAN for Text-to-Image Synthesis**](https://arxiv.org/abs/2303.05511) <br> *Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman, Sylvain Paris, Taesung Park* | <img height="50%" alt="image" src="https://user-images.githubusercontent.com/18592211/230898538-84da51ee-f686-422d-9892-c1c47ab10b75.png"></img> | [[Page](https://mingukkang.github.io/GigaGAN/)] |


## AnyModel
| Titile & Authors | Intro | Useful Links |
|:----|  :----: | :---:|
| [[**Jarvis (Project)**](https://github.com/microsoft/JARVIS)] <br> [**HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace**](https://arxiv.org/abs/2303.17580) <br> *Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang* |  <img style="height: 30%" src="https://github.com/microsoft/JARVIS/raw/main/assets/overview.jpg"><img> | [[Github]](https://github.com/microsoft/JARVIS) <br> [[Demo]](https://huggingface.co/spaces/microsoft/HuggingGPT) |
| [**TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs**](https://arxiv.org/abs/2303.16434) <br> *Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, Nan Duan* | ![intro](https://github.com/microsoft/visual-chatgpt/raw/main/assets/overview.png) | [[Github](https://github.com/microsoft/visual-chatgpt/tree/main/TaskMatrix.AI)] |
| [[**MQBench (Project)**](https://github.com/ModelTC/MQBench)] <br> [**MQBench: Towards Reproducible and Deployable Model Quantization Benchmark**](https://arxiv.org/abs/2111.03759) <br> *Yuhang Li* and Mingzhu Shen* and Jian Ma* and Yan Ren* and Mingxin Zhao* and Qi Zhang* and Ruihao Gong* and Fengwei Yu and Junjie Yan* | ![intro](http://mqbench.tech/assets/img/overview.png) | [[Github]](https://github.com/ModelTC/MQBench) <br> [[Page](http://mqbench.tech/)] |
| [[**Torch-Pruning (Project)**](https://github.com/VainF/Torch-Pruning)] <br> [**DepGraph: Towards Any Structural Pruning**](https://arxiv.org/abs/2301.12900) <br> *Gongfan Fang, Xinyin Ma, Mingli Song, Michael Bi Mi, Xinchao Wang* | ![intro](https://github.com/VainF/Torch-Pruning/raw/master/assets/intro.png) | [[Github](https://github.com/VainF/Torch-Pruning)] <br> [[Demo](https://colab.research.google.com/drive/1TRvELQDNj9PwM-EERWbF3IQOyxZeDepp?usp=sharing)] |
| [[**Only Train Once (Project)**](https://github.com/tianyic/only_train_once)] <br> [**OTOv2: Automatic, Generic, User-Friendly**](https://openreview.net/pdf?id=7ynoX1ojPMt) <br> *Tianyi Chen, Luming Liang, Tianyu Ding, Ilya Zharkov* | ![intro](https://user-images.githubusercontent.com/8930611/230513048-e07b09a2-b29b-49ad-a47f-52630337ab2a.png) | [[Github](https://github.com/tianyic/only_train_once)] |
| [[**Deep Model Reassembly (Project)**](https://github.com/Adamdad/DeRy)] <br> [**Deep Model Reassembly**](https://openreview.net/pdf?id=7ynoX1ojPMt) <br> *Xingyi Yang, Daquan Zhou, Songhua Liu, Jingwen Ye, Xinchao Wang* | ![intro](https://github.com/Adamdad/DeRy/raw/main/assets/pipeline.png) | [[Github](https://github.com/Adamdad/DeRy)] <br> [[Page](https://adamdad.github.io/dery/)] |

## AnyTask
| Titile & Authors | Intro | Useful Links |
|:----|  :----: | :---:|
| [[**X-Decoder (Project)**](https://github.com/microsoft/X-Decoder/)] <br> [**Generalized Decoding for Pixel, Image and Language**](https://arxiv.org/abs/2212.11270) <br> *Xueyan Zou, Zi-Yi Dou, Jianwei Yang, Zhe Gan, Linjie Li, Chunyuan Li, Xiyang Dai, Harkirat Behl, Jianfeng Wang, Lu Yuan, Nanyun Peng, Lijuan Wang, Yong Jae Lee, Jianfeng Gao* | ![intro](https://user-images.githubusercontent.com/11957155/210801832-c9143c42-ef65-4501-95a5-0d54749dcc52.gif)  | [[Github]](https://github.com/microsoft/X-Decoder/) <br> [[Page]](https://x-decoder-vl.github.io) <br> [[Demo]](https://huggingface.co/spaces/xdecoder/Demo)  |

## AnyX

...
